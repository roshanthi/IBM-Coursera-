{"nbformat_minor": 1, "cells": [{"source": "import numpy as np\n\nX_train = np.load('X_train_Gray.npy')\nY_train = np.load('Y_train_Gray.npy')\nX_test = np.load('X_test_Gray.npy')\nY_test = np.load('Y_test_Gray.npy')\n", "cell_type": "code", "execution_count": 18, "outputs": [], "metadata": {}}, {"source": "#Building the 1st Deep Convolution Neural Network\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nbatch_size=64\nepochs=20\nImg_size=100\nnum_classes=2\ninput_shape=(Img_size, Img_size, 1)\n\nmodel=Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3),             #1st layer - Convolution layer with 32 neurons and 3 x 3 matrix to scan the image\n                 activation='relu',\n                 input_shape=input_shape))   \nmodel.add(MaxPooling2D(pool_size=(2,2)))            #2ndlayer - Maxpooling layer with 2 x 2 matrix to scan\nmodel.add(Dropout(0.25))                            #to avoid overfitting dropping 25% of neurons in each iteration\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))       #3rd layer - Convolution layer with 64 neurons 3 x3 matrix to scan the image\nmodel.add(MaxPooling2D(pool_size=(2,2)))            #4th layer - Maxpooling layer with 2 x 2 matrix to scan\nmodel.add(Dropout(0.25))                            #to avoid overfitting dropping 25% of neurons in each iteration\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))      #5th layer - Convolution layer with 128 neurons 3 x3 matrix to scan the image\nmodel.add(MaxPooling2D(pool_size=(2,2)))            #6th layer - Maxpooling layer with 2 x 2 matrix to scan\nmodel.add(Dropout(0.25))                            #to avoid overfitting dropping 25% of neurons in each iteration\n\nmodel.add(Conv2D(256,(3,3),activation='relu'))      #7th layer - Convolution layer with 256 neurons 3 x3 matrix to scan the image\nmodel.add(MaxPooling2D(pool_size=(2,2)))            #6th layer - Maxpooling layer with 2 x 2 matrix to scan\nmodel.add(Dropout(0.25))                            #to avoid overfitting dropping 25% of neurons in each iteration\n\nmodel.add(Flatten())                        \n\nmodel.add(Dense(512, activation='relu'))            #Fully connected Dense layer with 512 neurons\nmodel.add(Dropout(0.5))                             #to avoid overfitting dropping 50% of the neurons in each iteration\nmodel.add(Dense(num_classes, activation='sigmoid')) #output layer\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_split=0.20)\nscore=model.evaluate(X_test,Y_test,verbose=0)\nprint('Test loss:', score[0])\nprint('Test Accuracy', score[1])\n\n\n\n\n\n", "cell_type": "code", "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}, {"output_type": "stream", "name": "stdout", "text": "Train on 17636 samples, validate on 4410 samples\nEpoch 1/20\n17636/17636 [==============================] - 405s 23ms/step - loss: 0.6020 - acc: 0.6697 - val_loss: 0.4839 - val_acc: 0.7683\nEpoch 2/20\n17636/17636 [==============================] - 398s 23ms/step - loss: 0.4445 - acc: 0.7945 - val_loss: 0.4142 - val_acc: 0.8209\nEpoch 3/20\n17636/17636 [==============================] - 396s 22ms/step - loss: 0.3300 - acc: 0.8594 - val_loss: 0.3662 - val_acc: 0.8654\nEpoch 4/20\n17636/17636 [==============================] - 396s 22ms/step - loss: 0.2501 - acc: 0.8979 - val_loss: 0.2196 - val_acc: 0.9124\nEpoch 5/20\n17636/17636 [==============================] - 386s 22ms/step - loss: 0.2078 - acc: 0.9187 - val_loss: 0.2199 - val_acc: 0.9141\nEpoch 6/20\n17636/17636 [==============================] - 388s 22ms/step - loss: 0.1850 - acc: 0.9285 - val_loss: 0.1765 - val_acc: 0.9355\nEpoch 7/20\n17636/17636 [==============================] - 380s 22ms/step - loss: 0.1716 - acc: 0.9361 - val_loss: 0.1643 - val_acc: 0.9406\nEpoch 8/20\n17636/17636 [==============================] - 388s 22ms/step - loss: 0.1641 - acc: 0.9383 - val_loss: 0.1768 - val_acc: 0.9288\nEpoch 9/20\n17636/17636 [==============================] - 388s 22ms/step - loss: 0.1552 - acc: 0.9432 - val_loss: 0.1945 - val_acc: 0.9217\nEpoch 10/20\n17636/17636 [==============================] - 390s 22ms/step - loss: 0.1448 - acc: 0.9475 - val_loss: 0.1689 - val_acc: 0.9407\nEpoch 11/20\n17636/17636 [==============================] - 391s 22ms/step - loss: 0.1371 - acc: 0.9500 - val_loss: 0.1474 - val_acc: 0.9468\nEpoch 12/20\n17636/17636 [==============================] - 392s 22ms/step - loss: 0.1335 - acc: 0.9503 - val_loss: 0.1451 - val_acc: 0.9490\nEpoch 13/20\n17636/17636 [==============================] - 390s 22ms/step - loss: 0.1296 - acc: 0.9509 - val_loss: 0.1428 - val_acc: 0.9463\nEpoch 14/20\n17636/17636 [==============================] - 393s 22ms/step - loss: 0.1273 - acc: 0.9540 - val_loss: 0.1450 - val_acc: 0.9446\nEpoch 15/20\n17636/17636 [==============================] - 391s 22ms/step - loss: 0.1199 - acc: 0.9551 - val_loss: 0.1403 - val_acc: 0.9466\nEpoch 16/20\n17636/17636 [==============================] - 391s 22ms/step - loss: 0.1139 - acc: 0.9581 - val_loss: 0.1444 - val_acc: 0.9478\nEpoch 17/20\n17636/17636 [==============================] - 383s 22ms/step - loss: 0.1113 - acc: 0.9579 - val_loss: 0.1543 - val_acc: 0.9466\nEpoch 18/20\n17636/17636 [==============================] - 387s 22ms/step - loss: 0.1080 - acc: 0.9598 - val_loss: 0.1407 - val_acc: 0.9483\nEpoch 19/20\n17636/17636 [==============================] - 392s 22ms/step - loss: 0.1026 - acc: 0.9606 - val_loss: 0.1477 - val_acc: 0.9475\nEpoch 20/20\n17636/17636 [==============================] - 391s 22ms/step - loss: 0.0971 - acc: 0.9651 - val_loss: 0.1508 - val_acc: 0.9488\nTest loss: 0.158624228293\nTest Accuracy 0.946298984035\n"}], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3.6", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.8", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}